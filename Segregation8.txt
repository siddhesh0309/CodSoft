import pandas as pd
from openpyxl import load_workbook
import os

template_path = "template.xlsm"
mapping_path = "mapping.xlsx"
output_folder = "segregated_by_status"

# Step 1: Load data from template (headers at row 4, data from row 9)
print("üîÑ Reading template file...")
df_template = pd.read_excel(template_path, sheet_name="Account Holder", engine="openpyxl", header=3, skiprows=[4, 5, 6, 7, 8])

# Step 2: Load mapping file
print("üîÑ Reading mapping file...")
df_mapping = pd.read_excel(mapping_path, dtype=str)

# Step 3: Merge mapping on Account Number
required_columns = {"Account Number", "Occupation", "GHO Code", "Status of Account"}
if not required_columns.issubset(df_mapping.columns):
    raise ValueError(f"‚ùå Mapping file is missing: {required_columns - set(df_mapping.columns)}")

print("üîó Merging mapping data...")
df_merged = df_template.merge(df_mapping[["Account Number", "Occupation", "GHO Code", "Status of Account"]],
                              on="Account Number", how="left")

# Step 4: Write updated data to template from row 9 (no headers)
print("üíæ Writing merged data into template...")
wb = load_workbook(template_path, keep_vba=True)
ws = wb["Account Holder"]

# Clear existing data rows (starting from row 9)
for row in ws.iter_rows(min_row=9, max_row=ws.max_row):
    for cell in row:
        cell.value = None

# Write new data back from row 9
for r_idx, row in df_merged.itertuples(index=False, name=None):
    for c_idx, value in enumerate(row, start=1):
        ws.cell(row=r_idx + 9, column=c_idx, value=value)

# Update header row (row 4) if needed ‚Äî optional
for i, col in enumerate(df_merged.columns, start=1):
    ws.cell(row=4, column=i, value=col)

wb.save(template_path)
print(f"‚úÖ Template updated: {template_path}")

# Step 5: Create segregated files by Status of Account
print("üìÅ Creating segregated files by Status of Account...")
os.makedirs(output_folder, exist_ok=True)

for status in df_merged["Status of Account"].dropna().unique():
    df_filtered = df_merged[df_merged["Status of Account"] == status]
    filename = os.path.join(output_folder, f"{status}_accounts.xlsx")
    df_filtered.to_excel(filename, index=False)
    print(f"‚úÖ Saved: {filename}")

print("üéØ All done.")



# Write headers in row 8 to avoid merged cells in row 4
for col_idx, col_name in enumerate(df_merged.columns, start=1):
    ws.cell(row=8, column=col_idx, value=col_name)

# Write data starting from row 9
for row_idx, row in enumerate(df_merged.itertuples(index=False, name=None), start=9):
    for col_idx, value in enumerate(row, start=1):
        ws.cell(row=row_idx, column=col_idx, value=value



# Special condition for Occupation = Sea Fearer
sea_mask = df_merged["Occupation"].str.strip().str.lower() == "sea fearer"

# Create filtered DataFrame for Sea Fearer rows only
df_sea = df_merged[sea_mask].copy()

# Define relevant TIN and TIN Issuing Country columns
tin_cols = [f"Foreign_TIN{i}" if i > 1 else "Foreign_TIN" for i in range(1, 9)]
tin_issuing_cols = [f"TIN_Issuing_Country{i}" if i > 1 else "TIN_Issuing_Country" for i in range(1, 9)]

# Step 1: If any TIN or dummy TIN exists, retain "Sea Fearer"
has_tin_or_dummy = df_sea[tin_cols].apply(
    lambda row: any(pd.notna(val) and str(val).strip() != "" for val in row), axis=1
)

# Step 2: If any TIN Issuing Country ‚â† "IN" and SC == "Y", then blank Occupation
has_foreign_tin_country = df_sea[tin_issuing_cols].apply(
    lambda row: any(str(val).strip().upper() != "IN" and str(val).strip() != "" for val in row), axis=1
)

# Apply the logic only to Sea Fearer rows
for idx in df_sea.index:
    if has_foreign_tin_country.loc[idx] and df_merged.at[idx, "SC"] == "Y":
        df_merged.at[idx, "Occupation"] = ""  # Clear it
    elif has_tin_or_dummy.loc[idx]:
        df_merged.at[idx, "Occupation"] = "Sea Fearer"  # Reinforce it (optional)

print("‚úÖ Sea Fearer logic applied only to relevant rows.")










# Step 1: Sea Fearer Mask
sea_mask = df_merged["Occupation"].str.strip().str.lower() == "sea fearer"
df_sea = df_merged[sea_mask].copy()

# Step 2: Define Foreign TIN and TIN Issuing Country columns
tin_cols = ["Foreign_TIN"] + [f"Foreign_TIN{i}" for i in range(2, 9)]
tin_issuing_cols = ["TIN_Issuing_Country"] + [f"TIN_Issuing_Country{i}" for i in range(2, 9)]

# Step 3: Determine if row has any TIN or dummy TIN
has_tin_or_dummy = df_sea[tin_cols].apply(
    lambda row: any(str(val).strip() not in ["", "nan"] for val in row if pd.notna(val)),
    axis=1
)

# Step 4: Determine if any TIN country ‚â† IN
has_foreign_country = df_sea[tin_issuing_cols].apply(
    lambda row: any(str(val).strip().upper() != "IN" and str(val).strip() != "" for val in row if pd.notna(val)),
    axis=1
)

# Step 5: Apply logic correctly
for idx in df_sea.index:
    sc_value = str(df_merged.at[idx, "SC"]).strip().upper()
    if not has_tin_or_dummy.loc[idx] and has_foreign_country.loc[idx] and sc_value == "Y":
        df_merged.at[idx, "Occupation"] = ""
    else:
        df_merged.at[idx, "Occupation"] = "Sea Fearer"



















from fastapi import FastAPI
from pydantic import BaseModel
from typing import List
from datetime import datetime
import requests

app = FastAPI()

UAT_API_ENDPOINT = ""
HEADERS = {"Content-Type": "application/json"}

# Pydantic models
class PANData(BaseModel):
    pan: str
    name: str
    fathername: str
    dob: str  # Format: dd-mm-yyyy

class PANRequest(BaseModel):
    User_ID: str
    Records_count: int
    Request_time: str
    Transaction_ID: str
    Version: str
    inputData: List[PANData]
    signature: str

@app.post("/verify_pan/")
def verify_pan(request: PANRequest):
    payload = {
        "header": {
            "User_ID": request.User_ID,
            "Records_count": request.Records_count,
            "Request_time": request.Request_time,
            "Transaction_ID": request.Transaction_ID,
            "Version": request.Version
        },
        "request": {
            "inputData": [data.dict() for data in request.inputData],
            "signature": request.signature
        }
    }

    # Sending to UAT endpoint (use PROD when ready)
    try:
        response = requests.post(UAT_API_ENDPOINT, json=payload, headers=HEADERS, verify=False)
        return {"status_code": response.status_code, "response": response.json()}
    except Exception as e:
        return {"error": str(e)}
















# Step 4: Apply corrected Sea-Fearer logic
print("‚öôÔ∏è Applying corrected Sea-Fearer occupation logic...")

sea_mask = df_merged["Occupation"].str.strip().str.lower().str.startswith("sea-fearer")
df_sea = df_merged[sea_mask].copy()

tin_cols = ["Foreign_TIN"] + [f"Foreign_TIN{i}" for i in range(2, 9)]
tin_issuing_cols = ["TIN_Issuing_Country"] + [f"TIN_Issuing_Country{i}" for i in range(2, 9)]

for idx, row in df_sea.iterrows():
    should_blank = False
    for tin_col, country_col in zip(tin_cols, tin_issuing_cols):
        country = str(row.get(country_col, "")).strip().upper()
        tin = str(row.get(tin_col, "")).strip().upper()
        
        if country and country != "IN":
            if tin and tin != "AAAAAAAAA":
                should_blank = True
                break
    
    if should_blank:
        df_merged.at[idx, "Occupation"] = ""
    else:
        df_merged.at[idx, "Occupation"] = "Sea-Fearer"

print("‚úÖ Sea-Fearer logic applied correctly.")









