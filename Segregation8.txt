import pandas as pd
from openpyxl import load_workbook
import os

template_path = "template.xlsm"
mapping_path = "mapping.xlsx"
output_folder = "segregated_by_status"

# Step 1: Load data from template (headers at row 4, data from row 9)
print("🔄 Reading template file...")
df_template = pd.read_excel(template_path, sheet_name="Account Holder", engine="openpyxl", header=3, skiprows=[4, 5, 6, 7, 8])

# Step 2: Load mapping file
print("🔄 Reading mapping file...")
df_mapping = pd.read_excel(mapping_path, dtype=str)

# Step 3: Merge mapping on Account Number
required_columns = {"Account Number", "Occupation", "GHO Code", "Status of Account"}
if not required_columns.issubset(df_mapping.columns):
    raise ValueError(f"❌ Mapping file is missing: {required_columns - set(df_mapping.columns)}")

print("🔗 Merging mapping data...")
df_merged = df_template.merge(df_mapping[["Account Number", "Occupation", "GHO Code", "Status of Account"]],
                              on="Account Number", how="left")

# Step 4: Write updated data to template from row 9 (no headers)
print("💾 Writing merged data into template...")
wb = load_workbook(template_path, keep_vba=True)
ws = wb["Account Holder"]

# Clear existing data rows (starting from row 9)
for row in ws.iter_rows(min_row=9, max_row=ws.max_row):
    for cell in row:
        cell.value = None

# Write new data back from row 9
for r_idx, row in df_merged.itertuples(index=False, name=None):
    for c_idx, value in enumerate(row, start=1):
        ws.cell(row=r_idx + 9, column=c_idx, value=value)

# Update header row (row 4) if needed — optional
for i, col in enumerate(df_merged.columns, start=1):
    ws.cell(row=4, column=i, value=col)

wb.save(template_path)
print(f"✅ Template updated: {template_path}")

# Step 5: Create segregated files by Status of Account
print("📁 Creating segregated files by Status of Account...")
os.makedirs(output_folder, exist_ok=True)

for status in df_merged["Status of Account"].dropna().unique():
    df_filtered = df_merged[df_merged["Status of Account"] == status]
    filename = os.path.join(output_folder, f"{status}_accounts.xlsx")
    df_filtered.to_excel(filename, index=False)
    print(f"✅ Saved: {filename}")

print("🎯 All done.")



# Write headers in row 8 to avoid merged cells in row 4
for col_idx, col_name in enumerate(df_merged.columns, start=1):
    ws.cell(row=8, column=col_idx, value=col_name)

# Write data starting from row 9
for row_idx, row in enumerate(df_merged.itertuples(index=False, name=None), start=9):
    for col_idx, value in enumerate(row, start=1):
        ws.cell(row=row_idx, column=col_idx, value=value



# Special condition for Occupation = Sea Fearer
sea_mask = df_merged["Occupation"].str.strip().str.lower() == "sea fearer"

# Create filtered DataFrame for Sea Fearer rows only
df_sea = df_merged[sea_mask].copy()

# Define relevant TIN and TIN Issuing Country columns
tin_cols = [f"Foreign_TIN{i}" if i > 1 else "Foreign_TIN" for i in range(1, 9)]
tin_issuing_cols = [f"TIN_Issuing_Country{i}" if i > 1 else "TIN_Issuing_Country" for i in range(1, 9)]

# Step 1: If any TIN or dummy TIN exists, retain "Sea Fearer"
has_tin_or_dummy = df_sea[tin_cols].apply(
    lambda row: any(pd.notna(val) and str(val).strip() != "" for val in row), axis=1
)

# Step 2: If any TIN Issuing Country ≠ "IN" and SC == "Y", then blank Occupation
has_foreign_tin_country = df_sea[tin_issuing_cols].apply(
    lambda row: any(str(val).strip().upper() != "IN" and str(val).strip() != "" for val in row), axis=1
)

# Apply the logic only to Sea Fearer rows
for idx in df_sea.index:
    if has_foreign_tin_country.loc[idx] and df_merged.at[idx, "SC"] == "Y":
        df_merged.at[idx, "Occupation"] = ""  # Clear it
    elif has_tin_or_dummy.loc[idx]:
        df_merged.at[idx, "Occupation"] = "Sea Fearer"  # Reinforce it (optional)

print("✅ Sea Fearer logic applied only to relevant rows.")


